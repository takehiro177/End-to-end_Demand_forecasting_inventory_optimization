{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9c29c66d-e2b1-41f1-aae5-b13fae9a94d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install missingno\n",
    "%pip install mlforecast\n",
    "%pip install window-ops\n",
    "%pip install numba\n",
    "%pip install optuna\n",
    "%pip install polars\n",
    "%pip install mapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53d97cb-d482-4617-8ea4-0dde95dd6ab2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b273e8d-7b1a-4771-998e-c36681ad08b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pls\n",
    "from typing import Literal\n",
    "pd.set_option('display.max_columns', None) \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean, expanding_std\n",
    "from window_ops.rolling import (rolling_mean, rolling_max, rolling_min, rolling_std, seasonal_rolling_mean, seasonal_rolling_std,\n",
    "                                rolling_correlation, rolling_cv, rolling_mean_positive_only, rolling_kurtosis, rolling_average_days_with_sales)\n",
    "from window_ops.ewm import ewm_mean\n",
    "\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.lgb_cv import LightGBMCV\n",
    "from mlforecast.target_transforms import Differences\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "from mlforecast.feature_engineering import transform_exog\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # Use this to disable training prints from optuna\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "mlflow.autolog(disable=True)\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c895ef56-9bbc-468b-8b24-6b7faf3d79fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    horizon=1\n",
    "    CV=True\n",
    "    distributed_optuna=False\n",
    "    n_folds=10\n",
    "    feat_cols=['current_week_of_year', 'current_year', 'current_month', 'retail', 'week', 'release_year', 'release_month', 'release_day', 'release_day_of_week', 'release_week_of_year', 'price', 'discount']\n",
    "    customer_cols=['retail_total_sales_qty', 'retail_total_customer_purchase']\n",
    "    gtrends_cols= [\n",
    "    \"long_sleeve\", \"culottes\", \"miniskirt\", \"short_sleeves\",\n",
    "    \"printed_shirt\", \"short_cardigan\", \"solid_color_top\", \n",
    "    \"trapeze_dress\", \"sleeveless\", \"long_cardigan\", \n",
    "    \"sheath_dress\", \"short_coat\", \"medium_coat\", \n",
    "    \"doll_dress\", \"long_dress\", \"shorts\", \n",
    "    \"long_coat\", \"jumpsuit\", \"drop_sleeve\", \n",
    "    \"patterned_top\", \"kimono_dress\", \"medium_cardigan\", \n",
    "    \"shirt_dress\", \"maxi\", \"capris\", \"gitana_skirt\", \n",
    "    \"long_duster\", \"yellow\", \"brown\", \"blue\", \n",
    "    \"grey\", \"green\", \"black\", \"red\", \n",
    "    \"white\", \"orange\", \"violet\", \"acrylic\", \n",
    "    \"scuba_crepe\", \"tulle\", \"angora\", \"faux_leather\", \n",
    "    \"georgette\", \"lurex\", \"nice\", \"crepe\", \n",
    "    \"satin_cotton\", \"silky_satin\", \"fur\", \n",
    "    \"matte_jersey\", \"plisse\", \"velvet\", \n",
    "    \"lace\", \"cotton\", \"piquet\", \"plush\", \n",
    "    \"bengaline\", \"jacquard\", \"frise\", \n",
    "    \"technical\", \"cady\", \"dark_jeans\", \n",
    "    \"light_jeans\", \"ity\", \"plumetis\", \n",
    "    \"polyviscous\", \"dainetto\", \"webbing\", \n",
    "    \"foam_rubber\", \"chanel\", \"marocain\", \n",
    "    \"macrame\", \"embossed\", \"heavy_jeans\", \n",
    "    \"nylon\", \"tencel\", \"paillettes\", \n",
    "    \"chambree\", \"chine_crepe\", \n",
    "    \"muslin_cotton_or_silk\", \"linen\", \n",
    "    \"tactel\", \"viscose_twill\", \"cloth\", \n",
    "    \"mohair\", \"mutton\", \"scottish\", \n",
    "    \"milano_stitch\", \"devore\", \"hron\", \n",
    "    \"ottoman\", \"fluid\", \"flamed\", \n",
    "    \"fluid_polyviscous\", \"shiny_jersey\", \"goose\"\n",
    "    ]\n",
    "    cat_cols=['category', 'color', 'fabric', 'season_category']\n",
    "    embed_cols = [f\"embed_{i+1}\" for i in range(512)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7713ca0-dac9-4203-a974-eee7dd32090f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df = spark.read.table(\"portfolio.end_to_end_demand_forecast.gold_demandforecast2to1_table\")\n",
    "imembed_df = spark.read.table(\"portfolio.end_to_end_demand_forecast.gold_imembed_table\")\n",
    "\n",
    "# Explode array into multiple columns \n",
    "imembed_df = imembed_df.selectExpr(\"image_embed\", \"explode(embeds) as embed_value\") \n",
    "# Select the columns dynamically \n",
    "select_expr = [F.col(\"image_embed\")] + [F.col(\"embeds\")[i].alias(CFG.embed_cols[i]) for i in range(512)]\n",
    "imembed_df = imembed_df.select(*select_expr)\n",
    "\n",
    "raw_df = raw_df.join(imembed_df, on='img_path', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0346d48-5c16-499e-97d1-c8faf931bfe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df.createOrReplaceTempView(\"raw_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38b01e4-a551-4ab3-924e-4bf220de2311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT * FROM raw_df) SELECT `y`,COUNT(*) `column_16bc594942` FROM q GROUP BY `y`",
       "commandTitle": "Distribution_of_target",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "y",
             "id": "column_16bc594940"
            },
            "y": [
             {
              "column": "*",
              "id": "column_16bc594942",
              "transform": "COUNT"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_16bc594942": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "393923bd-629f-4f28-b265-ea7c27fb331d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.875,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "y",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "y",
           "type": "column"
          },
          {
           "alias": "column_16bc594942",
           "args": [
            {
             "column": "*",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0805dbcf-b7b6-4001-ac41-6a3d278e4f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT * FROM raw_df\nWHERE raw_df.external_code = '324' AND raw_df.retail = 31) SELECT `ds`,SUM(`y`) `column_16bc594947` FROM q GROUP BY `ds`",
       "commandTitle": "Out_of_stock_sample",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "ds",
             "id": "column_16bc594944"
            },
            "y": [
             {
              "column": "y",
              "id": "column_16bc594947",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_16bc594947": {
             "type": "line",
             "yAxis": 0
            },
            "column_16bc594955": {
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": true,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "88b87a7c-5174-439c-b11a-6e60ea739749",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.9375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "ds",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "ds",
           "type": "column"
          },
          {
           "alias": "column_16bc594947",
           "args": [
            {
             "column": "y",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM raw_df\n",
    "WHERE raw_df.external_code = '324' AND raw_df.retail = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae765a61-d336-4ad0-a306-ff55ee1d01c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# custom preprocess pipeline\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_output(self, transform: None | Literal['default'] | Literal['pandas'] = None) -> BaseEstimator:\n",
    "        pass\n",
    "\n",
    "    def reduce_memory_usage_pls(self, df):\n",
    "      \"\"\" Reduce memory usage by polars dataframe {df} with name {name} by changing its data types.\n",
    "          Original pandas version of this function: https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65 \"\"\"\n",
    "      print(f\"Memory usage of dataframe is {round(df.estimated_size('mb'), 2)} MB\")\n",
    "      Numeric_Int_types = [pls.Int8,pls.Int16,pls.Int32,pls.Int64]\n",
    "      Numeric_Float_types = [pls.Float32,pls.Float64]    \n",
    "      for col in df.columns:\n",
    "          col_type = df[col].dtype\n",
    "          c_min = df[col].min()\n",
    "          c_max = df[col].max()\n",
    "          if col_type in Numeric_Int_types:\n",
    "              if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                  df = df.with_columns(df[col].cast(pls.Int8))\n",
    "              elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                  df = df.with_columns(df[col].cast(pls.Int16))\n",
    "              elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                  df = df.with_columns(df[col].cast(pls.Int32))\n",
    "              elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                  df = df.with_columns(df[col].cast(pls.Int64))\n",
    "          elif col_type in Numeric_Float_types:\n",
    "              if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                  df = df.with_columns(df[col].cast(pls.Float32))\n",
    "              else:\n",
    "                  pass\n",
    "          elif col_type == pls.Utf8:\n",
    "              df = df.with_columns(df[col].cast(pls.Categorical))\n",
    "          else:\n",
    "              pass\n",
    "      print(f\"Memory usage of dataframe became {round(df.estimated_size('mb'), 2)} MB\")\n",
    "      return df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X['ds'] = pd.to_datetime(X['ds'])\n",
    "\n",
    "        base_X = X.loc[:, ['ds', 'unique_id', 'y'] + CFG.cat_cols + CFG.feat_cols + CFG.embed_cols].copy()\n",
    "        base_X = pls.from_pandas(base_X)\n",
    "        X = pls.from_pandas(X)\n",
    "        gc.collect()\n",
    "\n",
    "        transformed_feats = transform_exog(X.select(['ds', 'unique_id'] + CFG.customer_cols + CFG.gtrends_cols),\n",
    "                                           lags=[1, 2], \n",
    "                                           #lag_transforms={\n",
    "                                           #    1: [(rolling_mean, 2), (rolling_average_days_with_sales, 2), (rolling_mean_positive_only, 2)],\n",
    "                                           #    },\n",
    "                                           num_threads=4)\n",
    "        transformed_feats = transformed_feats.fill_nan(-1)\n",
    "\n",
    "        transformed_X = base_X.join(transformed_feats, on=['unique_id', 'ds'], how='left')\n",
    "        transformed_X = transformed_X.to_pandas()\n",
    "        del base_X, transformed_feats;gc.collect()\n",
    "\n",
    "        # only use 1 lag gtrends to avoid data leakage\n",
    "        CFG.feat_cols.extend([col for col in transformed_X.columns if col not in ['ds', 'unique_id', 'y'] + CFG.cat_cols + CFG.feat_cols + CFG.gtrends_cols + CFG.customer_cols])\n",
    "\n",
    "        # fill out of stock quantity to 0 (reqired if tweedie loss)\n",
    "        transformed_X.loc[transformed_X['y'] < 0, 'y'] = 0\n",
    "\n",
    "        # convert date column to datetime64[ns] is nixtla requirement\n",
    "        transformed_X['ds'] = pd.to_datetime(transformed_X['ds'], dayfirst=True)\n",
    "      \n",
    "        return transformed_X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        X = self.transform(X, y)\n",
    "        return X\n",
    "    \n",
    "def make_pipeline(df):\n",
    "\n",
    "    cat_pipeline = ColumnTransformer([\n",
    "        ('cat_features', OrdinalEncoder(categories='auto', handle_unknown='error'), CFG.cat_cols)\n",
    "    ], verbose_feature_names_out=False, remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('train_data', Preprocessor()),\n",
    "        ('cat_features', cat_pipeline),\n",
    "    ]).set_output(transform='pandas')\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacc595e-5373-4a09-8f22-64d3ce97e859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.toPandas()\n",
    "pipeline = make_pipeline(raw_df)\n",
    "train_df = pipeline.fit_transform(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25d205e9-a7b0-48d7-b771-36ccfa249981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df[train_df['unique_id']=='142510AW17short coatbrownfur2017-10-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08de57b9-efbe-40cb-afbc-1f778a08a1ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# train and test split following paper experiment setting\n",
    "train_path = 'dbfs:/FileStore/tables/stfore_train.csv' \n",
    "train_ids = spark.read.options(header=True).csv(train_path).toPandas()\n",
    "test_path = 'dbfs:/FileStore/tables/stfore_test.csv' \n",
    "test_ids = spark.read.options(header=True).csv(test_path).toPandas()\n",
    "\n",
    "def get_unique_id(df):\n",
    "  df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d')\n",
    "  df['unique_id'] = df['external_code'].astype(str) + df['retail'].astype(str) + df['season'] + df['category'] + df['color'] + df['fabric'] + df['release_date'].astype(str)\n",
    "\n",
    "  return df['unique_id']\n",
    "\n",
    "train_ids = get_unique_id(train_ids)\n",
    "test_ids = get_unique_id(test_ids)\n",
    "\n",
    "train_data = train_df[train_df['unique_id'].isin(train_ids)].reset_index(drop=True)\n",
    "test_data = train_df[train_df['unique_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "del train_ids, test_ids; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "405f4603-1fcf-49cf-8c02-a0d9ab2572fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# black box hyperparameter optimization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest values of the hyperparameters using a trial object.\n",
    "    params = {\n",
    "            'objective': 'tweedie',\n",
    "            'tweedie_variance_power': trial.suggest_float('tweedie_variance_power', 1.1, 1.499, log=True),\n",
    "            #'objective': 'regression_l2',\n",
    "            'metric': 'rmse',\n",
    "            'learning_rate': 0.10,\n",
    "            #'zero_as_missing': False,\n",
    "            #'linear_tree': True,\n",
    "            'seed': 7113,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 30),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "            'subsample_freq': trial.suggest_int('subsample_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 3),\n",
    "            #'verbose': -1,\n",
    "            'force_row_wise': True,\n",
    "            }\n",
    "\n",
    "    if CFG.CV:\n",
    "      cv = LightGBMCV(\n",
    "          freq='W-MON', # weekly-dayofweek *note incorrect format leads nan loss\n",
    "          #target_transforms=[Differences([1])],\n",
    "          lags=[1],\n",
    "          # since available training window is 2 week, lag_transforms not available\n",
    "          #lag_transforms={\n",
    "          #    1: [(rolling_mean, 2), (rolling_average_days_with_sales, 2), (rolling_mean_positive_only, 2)],\n",
    "          #},\n",
    "          date_features=None,  # computing date features none for already computed\n",
    "          num_threads=14,\n",
    "      )\n",
    "\n",
    "      cv_hist = cv.fit(\n",
    "          train_data[['unique_id', 'ds', 'y'] + CFG.cat_cols + CFG.feat_cols + CFG.embed_cols],\n",
    "          static_features=CFG.cat_cols,\n",
    "          n_windows=CFG.n_folds,\n",
    "          h=CFG.horizon,\n",
    "          params=params,\n",
    "          eval_every=10,\n",
    "          early_stopping_evals=10,\n",
    "          num_iterations=1000,    \n",
    "          #compute_cv_preds=True,\n",
    "          metric='rmse',\n",
    "      )\n",
    "\n",
    "      cv_hist_df = pd.DataFrame(cv_hist, columns=['iterations', 'score'])\n",
    "      best_rmse = cv_hist_df['score'].min()\n",
    "      \n",
    "      return best_rmse\n",
    "    \n",
    "    else:\n",
    "      # custom validation here\n",
    "      # default cv setting is backtest split (note data leakage may happend depends on how data is split)\n",
    "      raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85599e7-cdc4-4241-898b-076e02441326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "if CFG.distributed_optuna:\n",
    "  study = optuna.create_study(direction='minimize')\n",
    "  # install distributed_optuna before turning on distributed_optuna in CFG\n",
    "  #distributed_study.optimize(objective, n_trials=20)\n",
    "else:\n",
    "  study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a76594b-7bb8-4e7a-8440-a091d7505d40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_cv_score = study.best_trial.value\n",
    "print(best_params)\n",
    "print(best_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7b9ce26a-9d21-424a-96d4-ece61a71efb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_cv_score = 0.8952321706690088  # stab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bcf32364-7020-4ead-94a0-ea3dbcbd14c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# self defined metric\n",
    "def MdAPE(\n",
    "    y_true: pd.Series,\n",
    "    y_pred: pd.Series):\n",
    "    \"\"\"Weighs the MAPE by the magnitude of the series values\"\"\"\n",
    "    abs_pct_err = abs(y_true - y_pred) / y_true\n",
    "    return abs_pct_err.median()\n",
    "\n",
    "def WAPE(y_true, y_pred, weights=None):\n",
    "    \"\"\"\n",
    "    Calculate Weighted Average Percentage Error (WAPE).\n",
    "\n",
    "    :param y_true: array-like of true values\n",
    "    :param y_pred: array-like of predicted values\n",
    "    :param weights: array-like of weights (optional), defaults to uniform weights\n",
    "    :return: Weighted Average Percentage Error\n",
    "    \"\"\"\n",
    "    # Ensure inputs are numpy arrays\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    else:\n",
    "        y_true = np.asarray(y_true)\n",
    "        \n",
    "    if isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    else:\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    # Set weights to ones if not provided\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(y_true)\n",
    "    else:\n",
    "        weights = np.asarray(weights)\n",
    "\n",
    "    # Calculate absolute percentage errors\n",
    "    ape = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "    # Calculate weighted absolute percentage error\n",
    "    weighted_ape = weights * ape\n",
    "\n",
    "    # Calculate weighted average percentage error\n",
    "    wape_value = np.sum(weighted_ape) / np.sum(weights)\n",
    "\n",
    "    return wape_value\n",
    "\n",
    "# lightgbm custom metric\n",
    "def custom_metric(y_true, y_hat):  \n",
    "    higher_is_better = False\n",
    "    score = WAPE(y_true, y_hat)\n",
    "    return 'WAPE', score, higher_is_better\n",
    "\n",
    "# mlflow metric\n",
    "def MdAPE_mlflow(eval_df, _builtin_metrics):\n",
    "  score = MdAPE(eval_df[\"prediction\"], eval_df[\"target\"])\n",
    "  return score\n",
    "\n",
    "def WAPE_mlflow(eval_df, _builtin_metrics):\n",
    "  score = WAPE(eval_df[\"prediction\"], eval_df[\"target\"])\n",
    "  return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d781cc30-505d-44b5-a3de-744802a736ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()  # check memory waste\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    train_ds = mlflow.data.from_pandas(train_data)\n",
    "    valid_ds = mlflow.data.from_pandas(test_data)\n",
    "    mlflow.log_input(train_ds, context=\"training\")\n",
    "    mlflow.log_input(valid_ds, context=\"testing\")\n",
    "\n",
    "    lgbm_params = {\n",
    "                'objective': 'tweedie',\n",
    "                'tweedie_variance_power': 1.3596343351145384,\n",
    "                'metric': 'rmse',\n",
    "                #'zero_as_missing': True,\n",
    "                #'linear_tree': True,\n",
    "                'learning_rate': 0.07,\n",
    "                'seed': 7113,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'reg_alpha': 7.682417976653917e-07,\n",
    "                'reg_lambda': 0.0023065465445564304,\n",
    "                'num_leaves': 28,\n",
    "                'max_depth': 11,\n",
    "                'colsample_bytree': 0.47478083397792714,\n",
    "                'subsample': 0.7413694185041535,\n",
    "                'subsample_freq': 7,\n",
    "                'min_child_samples': 2,\n",
    "                #'verbose': -1,\n",
    "                'force_row_wise': True,\n",
    "                'n_estimators': 250,  # choose number of estimators from result of optuna CV result\n",
    "                }\n",
    "\n",
    "    # log hyperparameters\n",
    "    for param_name, param_value in lgbm_params.items():\n",
    "        mlflow.log_param(param_name, param_value)\n",
    "    # log score for this hyperparameters\n",
    "    mlflow.log_metric(\"CV_RMSE\", best_cv_score)\n",
    "\n",
    "\n",
    "    fcst = MLForecast(\n",
    "        models={'dummy_model': LGBMRegressor(**lgbm_params)},\n",
    "        freq='W-MON',\n",
    "        lags=[1],\n",
    "        date_features=None,\n",
    "        num_threads=14,\n",
    "    )\n",
    "\n",
    "    # library managed training for recursive forecasting strategy (not flexible for prediction of fixd window and new sample, but confirmal prediction is not available so required to do it manually with MAPIE)\n",
    "    #mlf.fit(\n",
    "    #    train_data[['unique_id', 'ds', 'y'] + CFG.cat_cols + CFG.feat_cols],\n",
    "    #    static_features=CFG.cat_cols,\n",
    "    #    prediction_intervals=PredictionIntervals(n_windows=CFG.n_folds, h=CFG.horizon),\n",
    "        #max_horizon=CFG.horizon, # note!: CV be fitted using recursive strategy, setting max_horizon result in direct strategy and cv score can not be reproduced\n",
    "    #)\n",
    "\n",
    "    # custom training\n",
    "    train_data_prep = fcst.preprocess(\n",
    "        train_data[['unique_id', 'ds', 'y'] + CFG.cat_cols + CFG.feat_cols + CFG.embed_cols],\n",
    "        static_features=CFG.cat_cols,\n",
    "        max_horizon=1\n",
    "        )\n",
    "    X_tr, y_tr = train_data_prep[CFG.cat_cols + CFG.feat_cols + CFG.embed_cols], train_data_prep['y0']\n",
    "\n",
    "    test_data_prep = fcst.preprocess(\n",
    "        test_data[['unique_id', 'ds', 'y'] + CFG.cat_cols + CFG.feat_cols + CFG.embed_cols],\n",
    "        static_features=CFG.cat_cols,\n",
    "        max_horizon=1\n",
    "        )\n",
    "    X_te, y_te = test_data_prep[CFG.cat_cols + CFG.feat_cols + CFG.embed_cols], test_data_prep['y0']\n",
    "\n",
    "    regress = LGBMRegressor(**lgbm_params)\n",
    "    regress.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        categorical_feature=CFG.cat_cols,\n",
    "    )\n",
    "\n",
    "    y_tr_preds = regress.predict(X_tr)\n",
    "    signature = infer_signature(X_tr, y_tr_preds)\n",
    "\n",
    "    # construct an evaluation dataset from the test set\n",
    "    eval_data = X_te\n",
    "    eval_data[\"target\"] = y_te\n",
    "\n",
    "    model_info = mlflow.sklearn.log_model(regress, \"LGBM-regress-tweedie\", signature=signature) \n",
    "\n",
    "    result = mlflow.evaluate(\n",
    "        model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets=\"target\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=[\"default\"],\n",
    "        custom_metrics=[\n",
    "            mlflow.models.make_metric(\n",
    "                eval_fn=MdAPE_mlflow,\n",
    "                name=\"MdAPE\",\n",
    "                greater_is_better=False,\n",
    "            ),\n",
    "            mlflow.models.make_metric(\n",
    "                eval_fn=WAPE_mlflow,\n",
    "                name=\"WAPE\",\n",
    "                greater_is_better=False,\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f7bf76-20ba-4360-b247-389466039600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_data_prep[test_data_prep['unique_id'] == '5198100SS19culottesgreylinen2019-05-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf79ea8-b14f-47db-ab02-3903b9f02c1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# custom conformal prediction\n",
    "\n",
    "class MapieWrapper(mlflow.pyfunc.PythonModel):\n",
    "    # Initialize model in the constructor\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, context, model_input, alpha=0.15):\n",
    "        _, y_pis = self.model.predict(model_input, alpha=alpha)\n",
    "        return y_pis[:, :, 0]\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "  mapie_reg = MapieRegressor(estimator=regress, cv=\"prefit\", random_state=7113)\n",
    "  mapie_reg = mapie_reg.fit(X_tr, y_tr)\n",
    "\n",
    "  mapie_reg_wrapped = MapieWrapper(mapie_reg)\n",
    "\n",
    "  y_tr_pis = mapie_reg_wrapped.predict(None, X_tr)\n",
    "  signature = infer_signature(X_tr, y_tr_pis)\n",
    "  model_info = mlflow.pyfunc.log_model(\"MAPIE-LGBM-regress-tweedie\",\n",
    "                                       python_model=mapie_reg_wrapped,\n",
    "                                       signature=signature)\n",
    "\n",
    "  y_te_pis = mapie_reg_wrapped.predict(None, X_te.drop(columns=['target']))\n",
    "  result_df = pd.DataFrame(y_te.values, columns=['y'])\n",
    "  result_df['lo-85'] = y_te_pis[:, 0]\n",
    "  result_df['hi-85'] = y_te_pis[:, 1]\n",
    "\n",
    "  def flag_coverage(row):\n",
    "    if (row['y'] < row['hi-85']) & (row['y'] >= row['lo-85']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "      \n",
    "  result_df['covered_flag'] = result_df.apply(flag_coverage, axis=1)\n",
    "  result_df = pd.concat([result_df, test_data_prep[['unique_id', 'ds']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "  mlflow.log_metric(\"coverage_of_interval\", result_df['covered_flag'].sum() / len(result_df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "454c573f-62c3-44b0-b5ee-14c1803953f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(result_df).createOrReplaceTempView(\"conformal_prediction_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52070974-725e-48af-8479-e8a584137aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%sql WITH q AS (SELECT * FROM result_df) SELECT `ds`,SUM(`y`) `column_145a13f84`,SUM(`hi-85`) `column_145a13f88`,SUM(`lo-85`) `column_145a13f811`,`unique_id` FROM q GROUP BY `ds`,`unique_id`",
       "commandTitle": "forecast_test_result",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "unique_id",
             "id": "column_145a13f86"
            },
            "x": {
             "column": "ds",
             "id": "column_145a13f81"
            },
            "y": [
             {
              "column": "y",
              "id": "column_145a13f84",
              "transform": "SUM"
             },
             {
              "column": "hi-85",
              "id": "column_145a13f88",
              "transform": "SUM"
             },
             {
              "column": "lo-85",
              "id": "column_145a13f811",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "area",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_145a13f811": {
             "type": "area",
             "yAxis": 0
            },
            "column_145a13f84": {
             "type": "area",
             "yAxis": 0
            },
            "column_145a13f88": {
             "type": "area",
             "yAxis": 0
            },
            "hi-85": {
             "type": "area",
             "yAxis": 0
            },
            "lo-85": {
             "type": "area",
             "yAxis": 0
            },
            "y": {
             "type": "area",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "implicitDf": true,
        "rowLimit": 10000
       },
       "nuid": "6231ce54-9bcb-442f-923b-230138401136",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 13.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "ds",
           "type": "column"
          },
          {
           "column": "unique_id",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "ds",
           "type": "column"
          },
          {
           "alias": "column_145a13f84",
           "args": [
            {
             "column": "y",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_145a13f88",
           "args": [
            {
             "column": "hi-85",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_145a13f811",
           "args": [
            {
             "column": "lo-85",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "column": "unique_id",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM conformal_prediction_results AS CPR\n",
    "WHERE CPR.unique_id == '5198100SS19culottesgreylinen2019-05-06';"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3330401773421199,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "nixtla_fashion_demand_forecast_ML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
